# ü§ñ AI Voice Assistant with Face Recognition (Offline LLM)

## üìå Project Overview

This project is a desktop-based AI Assistant that integrates:

-   üß† Local Large Language Model (LLM) via Ollama\
-   üé§ Voice input & speech output\
-   üì∑ Real-time face recognition\
-   üñ• Modern GUI using PySide6

The system runs fully offline using a locally hosted model (`gemma:2b`)
without any cloud APIs.

------------------------------------------------------------------------

## üöÄ Key Features

-   üí¨ GPT-style conversational chatbot
-   üß† Local AI inference using Ollama
-   üéô Speech-to-text (microphone input)
-   üîä Text-to-speech response
-   üë§ Face recognition authentication
-   üñº GUI-based desktop interface
-   ‚ö° GPU acceleration support (if available)

------------------------------------------------------------------------

## üèó Project Structure

AI-ML-Chatbot/ ‚îÇ ‚îú‚îÄ‚îÄ ui/ ‚îÇ ‚îî‚îÄ‚îÄ main_window.py \# Main GUI entry point ‚îÇ
‚îú‚îÄ‚îÄ face/ ‚îÇ ‚îú‚îÄ‚îÄ face_thread.py ‚îÇ ‚îî‚îÄ‚îÄ register_runtime.py ‚îÇ ‚îú‚îÄ‚îÄ voice/ ‚îÇ
‚îú‚îÄ‚îÄ voice_thread.py ‚îÇ ‚îî‚îÄ‚îÄ voice_utils.py ‚îÇ ‚îú‚îÄ‚îÄ chatbot/ ‚îÇ ‚îú‚îÄ‚îÄ encodings/
‚îÇ ‚îî‚îÄ‚îÄ encodings.pkl \# Pre-generated face encodings ‚îÇ ‚îú‚îÄ‚îÄ chatbot_api.py
\# Ollama API integration ‚îú‚îÄ‚îÄ encode_faces.py \# Generate face encodings
‚îú‚îÄ‚îÄ recognize_face.py ‚îú‚îÄ‚îÄ register_face.py ‚îú‚îÄ‚îÄ auto_register.py ‚îú‚îÄ‚îÄ
AI_Assistant.spec \# PyInstaller build config ‚îú‚îÄ‚îÄ requirements.txt ‚îî‚îÄ‚îÄ
README.md

------------------------------------------------------------------------

## üß† AI Model Details

This project uses:

-   Ollama for local model hosting
-   Model: `gemma:2b`

Advantages: - No API key required - No internet required after setup -
Fully offline inference - Faster demo performance on CPU systems

------------------------------------------------------------------------

## ‚öôÔ∏è Installation (Source Code Version)

### 1Ô∏è‚É£ Install Python (3.10 recommended)

### 2Ô∏è‚É£ Install Dependencies

pip install -r requirements.txt

> ‚ö† On Windows, `dlib` and `PyAudio` may require precompiled wheels.

------------------------------------------------------------------------

### 3Ô∏è‚É£ Install Ollama

Download from: https://ollama.com

------------------------------------------------------------------------

### 4Ô∏è‚É£ Download Model

ollama pull gemma:2b

------------------------------------------------------------------------

### 5Ô∏è‚É£ Run Application

python ui/main_window.py

------------------------------------------------------------------------

## üì¶ Running EXE Version (College Demo)

If using the compiled `.exe`:

1.  Install Ollama\
2.  Run: ollama pull gemma:2b\
3.  Ensure Ollama is running\
4.  Double-click `AI_Assistant.exe`\
5.  Allow microphone and camera permissions

------------------------------------------------------------------------

## üñ• Hardware Requirements

Minimum (Tested on):

-   Intel i5
-   16GB RAM
-   Windows 10/11
-   Webcam & Microphone

Recommended:

-   GPU (NVIDIA RTX series)
-   16GB+ RAM

------------------------------------------------------------------------

## üîß Technologies Used

-   Python
-   PySide6 (GUI)
-   OpenCV
-   dlib
-   face-recognition
-   SpeechRecognition
-   PyAudio
-   pyttsx3
-   Ollama (Local LLM runtime)

------------------------------------------------------------------------

## üéì Academic Purpose

This project demonstrates:

-   Integration of computer vision and NLP
-   Local LLM deployment
-   Real-time face authentication
-   Voice-based AI interaction
-   Desktop application packaging using PyInstaller

------------------------------------------------------------------------

## üìå Notes

-   Encodings are pre-generated (`encodings.pkl`)
-   If dataset changes, run:

python encode_faces.py

to regenerate encodings.

------------------------------------------------------------------------

## üë®‚Äçüíª Author

Faiz\
AI/ML Project -- Academic Submission
